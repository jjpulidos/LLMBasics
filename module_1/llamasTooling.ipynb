{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langchain_community langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed355e20-d66d-4612-a9a1-ba2a89bccdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langfuse langchain --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b35e977-24eb-4326-9364-a3cb06d449e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LANGFUSE_PUBLIC_KEY:  ········\n",
      "LANGFUSE_SECRET_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea451a7-2e77-469a-8c34-3d7ab00653dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# Initialize Langfuse client\n",
    "langfuse = Langfuse(\n",
    "    public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    host=\"http://localhost:3000\"\n",
    ")\n",
    "\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "    secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "    host=\"http://localhost:3000\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "ollama_model = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1280e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¿Dónde está mi llama? (Where is my llama?)', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-10-15T01:26:34.295075Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 8184361792, 'load_duration': 7609508833, 'prompt_eval_count': 31, 'prompt_eval_duration': 149471000, 'eval_count': 15, 'eval_duration': 421245000}, id='run-55d44a28-6895-4153-95ee-0e631f181a82-0', usage_metadata={'input_tokens': 31, 'output_tokens': 15, 'total_tokens': 46})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Now we are using ChatPromptTemplate instead of PromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | ollama_model\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"Spanish\",\n",
    "        \"input\": \"Where is my llama?.\",\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64d0cdb-d886-46fe-8464-56e7b1797d1a",
   "metadata": {},
   "source": [
    "Now lets try to muliply 2 numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040d7588-8eb8-4322-b895-97813bd3d72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To multiply these two numbers, I'll perform the calculation:\\n\\n5674356 × 43526789 = \\n\\nCalculating...\\n\\nThe result is: **246,911,111,444**\\n\\nLet me know if you need any further assistance!\", additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-10-15T01:29:49.828817Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 2363333500, 'load_duration': 29677083, 'prompt_eval_count': 53, 'prompt_eval_duration': 891677000, 'eval_count': 49, 'eval_duration': 1438450000}, id='run-57bdf0a1-3d0d-49ee-b59c-33997247233f-0', usage_metadata={'input_tokens': 53, 'output_tokens': 49, 'total_tokens': 102})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that multiplies 2 numbers, the user is going to provide 2 numbers and you have to muliply them.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "multiply_chain = multiply_prompt | ollama_model\n",
    "multiply_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"5674356 and 43526789\",\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd16249-dd2b-4eee-82c9-97aa10c75e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246986496322884"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5674356 * 43526789"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9080b35-e466-4d23-8e2d-656386a06138",
   "metadata": {},
   "source": [
    "Oh no! My llama does not work really well at multiplying numbers.\n",
    "\n",
    "So let's bring some arithmetical tools to my llama chain so the model can use it by demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ede3f4-fbb6-49cd-a610-6c5f981fb0b2",
   "metadata": {},
   "source": [
    "## Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bafd7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "my_tools = [multiply]\n",
    "ollama_with_tools = ollama_model.bind_tools(my_tools)\n",
    "tool_node = ToolNode(my_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f93c32-a493-4195-b96e-01ae4d4e1000",
   "metadata": {},
   "source": [
    "ToolNode operates on graph state with a list of messages. \n",
    "It expects the last message in the list to be an **AIMessage** with **tool_calls** parameter.\n",
    "\n",
    "**Let's first see how to invoke the tool node manually:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d44422cc-7456-410e-bff7-bbc7f5470605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='100', name='multiply', tool_call_id='tool_call_id')]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "message_with_a_tool_call = AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"multiply\",\n",
    "            \"args\": {\"a\": 20, \"b\": 5},\n",
    "            \"id\": \"tool_call_id\",\n",
    "            \"type\": \"tool_call\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "tool_node.invoke({\"messages\": [message_with_a_tool_call]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d378d5-b480-48a4-a284-c0585e532449",
   "metadata": {},
   "source": [
    "We got the result as the content, and it is correct. Note we are not using any model, just calling the tool manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aff5292c-0417-437d-89c6-626db3c4fb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-10-15T01:32:17.886753Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'multiply', 'arguments': {'a': 2, 'b': 3}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 2177728625, 'load_duration': 31231000, 'prompt_eval_count': 174, 'prompt_eval_duration': 1513143000, 'eval_count': 22, 'eval_duration': 632297000}, id='run-00db1804-795a-4f54-99ed-8ce7abd16863-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'c0500bfb-21d0-421a-b774-39877154a578', 'type': 'tool_call'}], usage_metadata={'input_tokens': 174, 'output_tokens': 22, 'total_tokens': 196})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "tool_call = ollama_with_tools.invoke(\n",
    "    [HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"JuanPulido\")], \n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    "    )\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebe838-78ed-4a2c-b38f-a0841dc27273",
   "metadata": {},
   "source": [
    "Note in LangFuse that this is not a RunnableSequence but a ChatOLlama instead, this because we are not chaining a prompt and a model, but we just added some tools to the model and just invoke it.\n",
    "\n",
    "In this case, in the invoke output we can see the **tool_calls** field which contains the function calling to our previous defined **multiply** python function.\n",
    "\n",
    "As we are not using the tool_node to run manually the function we cannot get the result. But lets do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c1073fc-f2f7-4d6f-bf75-32c7cf36e2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='6', name='multiply', tool_call_id='c0500bfb-21d0-421a-b774-39877154a578')]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node.invoke({\"messages\": [tool_call]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc503b54-258f-4a53-9e70-d646d4444029",
   "metadata": {},
   "source": [
    "### Putting the function calling in a Graph\n",
    "\n",
    "Now we saw some of the functionalities when using Sequences and chains in LangChain, but if we want to build a product-ready app, we will need something more than just **Micro-Orchestration** but **Macro-Orchestation**, and there is when LangGraph comes to play.\n",
    "\n",
    "Let's build a simple Graph using our previously Ollama model + tools\n",
    "\n",
    "Note that here our main Node to be defined is the invocation of our ollama model passing as input the messages state from LangGraph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c418bfc2-83d0-4b9b-abb0-dde473ad8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91d4d305-7250-4730-bddf-1acf385171ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADqALoDASIAAhEBAxEB/8QAHQABAAICAwEBAAAAAAAAAAAAAAUGBAcCAwgBCf/EAFMQAAEDAwEDCAYDCgoHCQAAAAEAAgMEBREGBxIhExQVIjFBlNMIFlFUVtEXVWEkMjZCcXSBk5WyIyYzNFJ1kZKz0hglU2Ryc7EnREZXYoPB4fD/xAAaAQEBAAMBAQAAAAAAAAAAAAAAAQIDBAUG/8QANREBAAECAgYGCQQDAAAAAAAAAAECEQNRBBIUITGRQWFikqHRBRMjM1JxseHwIlOBwTJC8f/aAAwDAQACEQMRAD8A/VNERAREQEREBdVRUw0kfKTyshjH40jg0f2lQ1zudZcLhJabQ9sM0Qa6rr5I99lM13EMaM4dKRxAPBoIc4HLWv6qfZ9YmP5asomXesIw6run3TKeOeBdkNGe5oA4DAGFviimIviTbqhbZs86psoODd6AH85Z809arL9cUHiWfNPVay/VFB4ZnyT1Vsv1PQeGZ8lfY9fgu49arL9cUHiWfNPWqy/XFB4lnzT1Vsv1PQeGZ8k9VbL9T0HhmfJPY9fgbj1qsv1xQeJZ809arL9cUHiWfNPVWy/U9B4ZnyT1Vsv1PQeGZ8k9j1+BuPWqy/XFB4lnzWVR3SjuGea1cFTgZPIyNfj+wrF9VbL9T0HhmfJYtboPTlwA5ax0BeMFsrIGskYe4te0BzT9oIT2M9M+H2TcnkVWdzzRQ5SWqqLnYex7qg8pUUQz98XnjJEO8uy9vaS4Z3bQCHAEHIPYQtddGrvibxJZ9REWtBERAREQEREBERAWLc6+O1W2rrZs8lTQvmfjt3WtJP8A0WUo3UttdetO3W3sID6uklgaT2Zcwt/+VnRETVEVcCGHoagkodMUT6jdNdVt55Vvbnrzydd549wJwB3AADAACnlE6UuLbvpi1VrQWieljeWuGC0loy0juIOQR9illlizM4lWtxus8RVrXu0bTuzKzw3PUlxFvpJ6hlJDuwyTyzTOBLY4442ue9xDXHDWk4BPcrKtVekVarTc9JWp9ztmqauakucdTQ1+j6Z1RX2yoayTdqQxoJLQC5hG68HlAC0jJGpEVrD0ptM6Yv8AoGmhgr7jadUNqpuf0tsrJXwxwxuIxCyBz3OL27pbgOYAXEY4qz6o9IHQOi9TMsF7v3R1xJia7laOo5CIy45MSTiMxRl28Mb7h2rTQuOv20OxHXustN3i6V1mrLpFdobZbC+ubDPDLDSzyUkeS1zmtjL2t+9LzwHYKt6QdBrHaPRbTbXW2XX1dNV0UXqpa7PDNBa3U5p2Pe6pLS1r5hJyodFMS7qtDGkkIPS2oNt+jNM6vfpWuuk3rEyOGY26lt9TUy8nK5zWPxFG7LctILuxvDeLd4Zg9j/pB2ra1qLVVmp6GvoauzXOoo4uVoKpsc0MQjHKOlfC1jHl0h/gi7fAAOCOKjNnFpraj0gtYajntNdS0VdpiyR01ZW0kkW84OqnSxZcB125j32drSRkBdOxWouGjdom0bS9109eoJLrqarvdFdW0L326WmlhhLfugDca8FjmlhOc49qDeCIiDjIxsrHMe0PY4EOa4ZBHsKregpDBba20udvdEVklCwkknkgGvhBJ7SIpIwT3kEqzKsaJHLz6kuAzyVbdpHRkjGRFHHTk/k3oHYPeMLoo93XE8N3P/l1jhKzoiLnQREQEREBERAREQEREFWLxoisqXyNxp+qmdO6RoJ5lM8kvLvZE52XF34rnOJ6py35qvZrozaTzKq1Fpuz6l5Fh5tNcKSOp3GOwTuFwOAcA8O3grUq1Ls/tbZHyW91XZHyElwtdS+CNxJySYwdzJPEndycnjxK6NajE31zac+N/n+b13TxVv8A0a9k/wD5b6W/ZEH+VWPR2zLSOz19U/S+mbTp51WGiodbKOOAyhud3e3QM43jjPtK4nRNQST6034fYJofKT1JqPiq/frofKT1eH8fhJaM1oRVf1JqPiq/frofKVT1Pb7raNb6NtNPqm8Gku01UypL5Yd8COndI3d/g+HWAzwPBPV4fx+ElozbUUZqTTNo1jZp7TfbZSXi11G7ytHXQtlik3XBzd5rgQcOAI+0BRXqTUfFV+/XQ+UnqTUfFV+/XQ+Unq8P4/CS0ZoBno37KYnEs2caXYSC3LbTAOBGCPve8EhZlj2EbONMXamulo0Lp62XKmdvwVdJbYY5YnYxlrg3IOCexSfqTUfFV+/XQ+UjtA09T1a+7Xm4xcMxTVzo2O/KItzI+w8D7E1MOONfhP2LRm7brfX3Opms9kmZJXA7lVVNO8yhB7d4jhyuPvWdvYTgdszarZT2a20tBSM5Ompo2xRtzkhoGBk95+1fbfbqW00cVJRU0VJSxDDIYGBjGj7AOAWSsK64tq08Pr+eBcREWpBERAREQEREBERAREQEREBERAWvddEfSnszyTnnFwx4R/2rYS17rrP0p7M+z+cXDtAz/NH9n/0g2EiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIC15rsf9qmzLiB903DgRxP3G/sWw1rzXePpV2Ze3nNwxw/3N6DYaIiAiIgIiICIiAiIgIiICL45wY0ucQ1oGSSeACpR1he7sBUWW2UJtr+MNRcKl8ckze54jbGd1p7Rk5I7QFuw8KrFvq+S2uuyKkdO6w9wsfi5vLTp3WHuFj8XN5a3bLXnHOCy7oqR07rD3Cx+Lm8tOndYe4WPxc3lpstecc4LLuipHTusPcLH4uby06d1h7hY/FzeWmy15xzgsu6KkdO6w9wsfi5vLTp3WHuFj8XN5abLXnHOCy7rwf6Qnp0VezDb1R2O5bOZpKjS9XUGFzbs0c/inhLIpGjkDuZa4Oxk8ctz3r1z07rD3Cx+Lm8tag2nej/NtV2s6L17drfZhcNNuJNO2olLKwNO/E2TMfYx+Xdhzkg8E2WvOOcFnoTTVxrLxpy1V9xtzrRcKqkinqbe6TlDSyuYHPiLsDe3SS3OBnHYFJKkdO6w9wsfi5vLTp3WHuFj8XN5abLXnHOCy7oqR07rD3Cx+Lm8tOndYe4WPxc3lpstecc4LLuipHTusPcLH4uby06d1h7hY/FzeWmy15xzgsu6KkdO6w9wsfi5vLTp3WHuFj8XN5abLXnHOCy7oqR07rD3Cx+Lm8tcm6g1dGd59rs0zR2sZXStcfyExEZ//cO1NlrzjnBZdUUfY71Bf7e2rga+PrOjkhlGJIpGnDmOHEZBHcSDwIJBBMguWqmaZmmeKIvVBLdM3cg4Io5iCP8AgKr2mQBpu1AAACkiwB/wBWHVX4MXj8zm/cKr2mvwctX5pF+4F34PuZ+f9L0JJEWDZ75b9Q0XPLXWwXCk5WSHl6aQPZvxvLHtyOGWua5p9hBWSM5EXVV1UVDSzVM7tyGFjpHuwThoGScDj2BB2oo3TOo7drDT1tvloqOd2u407Kqln3HM5SJ7Q5rt1wDhkEcCAVJICIofUWrrTpN1qbdavmpuldHbaMcm9/K1Dw4sZ1QcZDHcTgcOJUEwir0e0CwSzaniZX70mmiBdW8jJ9zZhE4/F6/8G5rupvduO3gpWy3ik1DZ6G6UEvL0FdBHU08u65u/G9oc12HAEZBBwQD7UGYiIqCIoe/6utOl6qzU1zq+bTXitFvoW8m9/LTlj5AzLQd3qxvOXYHDtyQoJhFD2LV1p1LXXqjttXzmos1XzGuZyb2cjPybJNzLgA7qyMOW5HHtyCphAREVBERBhbOz19TjuF3fgf8Aswn/AKkq4Kn7Ov5XVH9cP/wIVcFzaT72f4+kLPFF6q/Bi8fmc37hVe01+Dlq/NIv3ArDqr8GLx+ZzfuFV7TX4OWr80i/cC34PuZ+f9HQzqiEVMEkTnPY2RpaXRuLXDIxkEcQftC8daJFZsw9Fa+X/T95utNdqu91FqdVVtxmqoaBj7y+ndOyKRxYx4Y8uLgAXO6zs8V7JVEpthuh6Su1DUx2GP8AjAyVlzpnzyvpqgSkOkPIF5ja5xaCXNaCT3qTF0aQ2kam1B6PF81Hb9O6hvWpIpNFV17bBfq11fJRVVPJGxlQHPyQxwldln3pMfADipC5Uty2Y6o0NQUusb7qim1farnFc4bxXuq2SOiojO2qhDuEI3hulrMNxI0YyAtx6O2K6L0GLl0PZGNdcYRTVclbUS1kksIBAiL5nvdyeCeoDu8exdWidhmh9nd0fcbDYm0ta6A0rZZqmaoMMJOTFEJXuETMgdRm6OA4cFNWRg+jQQfR62b4Of4v0XZ/yWqK263i6VGqtnOjKK81enLfqe41EVfc6CQRVAjhpnzNgjkx1HSOAG8OtgHHapil2b3jQdFDadm9Tp/TVgaXzOoblbamuLZXuJcYyKuMMZ2YYBgHOO3CyKrZvU6+09U2jaX0HqalM0c9MLZQT0Jge3OHhxqJHh4zwcxzSBkccq77WFC2mWMaRtOmtD2q8a2vt7vdxmnoY2akfTTGOKHMomrSHSNgYC12BvPLiAMjIWvLRqC/XjRWgaPUlXJWXGybWBaOXqKnnMpjiM4Y1826zlXNDt3fLWl2ASASt8O9HnQL7HT2o2WYU9PWOr4pxcqoVTJ3MDHPFQJeVy5gDT18EAA9i7B6Puz5ula7TTNNwxWOtq2V8tHFPKxraloaGzRkPBjfhjeswtJOSckknHVm41dVwST1PpP8jXVtuqIJaepiqbdVPpp43x2mCRhbIwhzeswZweIyDwJWLpGkuu0nXmmrNctW6lo7c/ZtabnLHbLrLTOlq3yytM7ntO8X47TnrYG9vYAG8qvZVpWtvl8vEtpb0lfLf0Xcp45pGc6p93d3XhrgC4N4B+N4DgCAsix7OtPabu1Lc7db+b11NaYbHFLy0jt2jicXRxYc4g4Lid4jeOeJKuqPLds2lXTUmmtlMmu9V3+x6auFjruWu1iklhnrbpDM2ONsskLS8ZibI8NGA92c5xhegPRyp9QU+xXS41Sa436SGSapdcnvdUu35XvaZN8ktcWOaS38UndAAGBT9pXo8Gqt2lqDRdjsvMLLDUwMhuN6ulBNGyV7XkMnpnlzmlzSS14dk7uC3CmNDaB2p6L0jbbRHrSwVr4GyGSS7WurrpGl0r3iNsxrGOcxjXNY0vBdhuSeOBIiYneOnanLcdV7ZdHaE6buenrDV2uuutTLaKp1JUVssL4WMhEzMPa1olc8hpBOBngFq6j1BcrjcNF2i5XSovTNN7WZ7LSXOscHzzwMoKh7BI/hvvaZHRl3adzjxyt61+ysbQLRDT7Rxa79WUdSZ6GrskFTbH0wLQ07rxUPkDjxyWvAIwCOCyqjYjoep0VRaSdp6nbYKKobV01NE+SN0U7XFwmbI1weJMucS/e3jvHJOSraZ3jUFNqej0jaPSCuFdPdII/WmOnYbJI2OtMs1JRRRNic7g1znvaA48BnPcqHe9Ua82d6X2y2OsuV3t01DpekvduFVqB91qqKR8ssbi2qLGPG9ybSWdYAg4OHL0/eNjOi79X6irK+wwVE+oaeOmupMkjW1TI8cmXNDg3fbutw8AOG6MHgFDx+jbs6jpbpB6vve260LrbXyS3CqfLV07nNduyyOlL3kFjcOJLmjIBAJBk0yNdO0BWP29Q6QfrrWhslbpZ94qIxfpmyOq2VLIhIyQEOjGJHExxlrCQ3q4GFWLHq++7U9n2zSxx1upbprSotlZWVD7VfjZoXQQ1Ap+cVU7GOc528GhrWtOS55cMYXp/1QtHrbFqbmn+vIqB1sZVco/hTOkbIWbud375rTnGeHbhVOp9HrQFXabNbXWFzKWztmjouRrqmKSNkr9+WMyNkD3sc7iWOJafYrqz0DF9GbVV31psP0xdb7Umtuzmz09RUOILpTDUSwhxIABJEYJOBk5K2eoPRuiLHs9sos+nbey1WsTSTso4XOMUbpHF7wxpJDGlxJ3W4aMnACnFnG6BhbOv5XVH9cP8A8CFXBU/Z1/K6o/rh/wDgQq4Ln0n3s/x9IWeKL1V+DF4/M5v3Cq9pr8HLV+aRfuBXGogjqoJIZW78UjSxzT3gjBCocNLf9M08NubZJr5T07GxQ1lHUQtc9gGG8o2V7MPwOOCQe3hndG7R5iaJovab33zb6rG+LJ1FCdLX74MuviqLz06Wv3wZdfFUXnrfqdqO9HmWTaKE6Wv3wZdfFUXnp0tfvgy6+KovPTU7Ud6PMsm0UJ0tfvgy6+KovPTpa/fBl18VReemp2o70eZZNooTpa/fBl18VReenS1++DLr4qi89NTtR3o8yybRQnS1++DLr4qi89R1frevtd2tdsqdKXWOtubpGUkXL0h5QsYXv4ibAw0E8SE1O1HejzLLYihOlr98GXXxVF56dLX74MuviqLz01O1HejzLJtFCdLX74MuviqLz06Wv3wZdfFUXnpqdqO9HmWTaKE6Wv3wZdfFUXnp0tfvgy6+KovPTU7Ud6PMsm0UJ0tfvgy6+KovPTpa/fBl18VReemp2o70eZZNooTpa/fBl18VReeuTbjqCY7rNI10Tz2OqaulawflLJXH+xpTU7Ud6PNLMzZ1/K6o/rh/+BCrgobS1ifYbdIyeVs9ZUzPqaiRgIYZHdzQeO6AA0Z7gplcGPVFeJM08CeIiIudBERAREQEREBERAWvtcDO1HZrwzior+7s+5H/AGfJbBWvddNztT2ZnBOKi4cQOz7keg2EiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIC15rsj6VNmWTx5zcMcP9zethrX2ud76UtmmC7HOK/O6OH80f2oNgoiICIiAiIgIiICIiAiIgIiICIiAiIgIi4ve2JjnvcGMaMlzjgAe0oOSKtTbTNIU73Mk1RZ2uacOHPoiWn2HrcF1fSro34qs/jY/mujZ8af8ASeUraclqWlNoe1XRFHtY0HHUawsEEtuq7hHWMkucDXUr+bPYWyAvG4d7q4Pfw7VsH6VdG/FVn8bH81+ffpT+jpp/aB6T+nbvp692xum9UzCS+VUFVHuUMkeDNI45wOUYARk9Z5cO9Nmx/gnlK6s5P0noK+mutDT1tFURVlHUxtmgqIHh8csbhlr2uHBzSCCCOBBXeqVaNf6CsNporZQajstLQ0UDKangZWx7scbGhrWjrdgAAWX9Kujfiqz+Nj+abNj/AATyk1ZyWpFVhtT0af8AxVZgO8mujAH6d5T1tutFeaYVNvrKeupz2S00rZGH9IJCwrwsSiL10zHzhLTDLREWpBERAREQEREBERAREQEREERqnU1HpGyz3KtLixmGsij4vmeeDWNHtJ9vAcSSACR581Pe6/WlW6a8y8vBvb0VvaTzaEd3V7HuH9NwznON0dUW3bbdH1er7ba8nkKKj54W54GSVzo2u/K1scgH/MKoy+59E6HRhYUY9Ufqq8IJmz4xjY2hrGhrR2ADAX1EXvsBFr+67arPaqmtc63XeotFBOaasvlPSh1FTyNduvDnb28Q08HOa0gEHJ4Fdd6232myVl+ifaL1VU9ilbHcq2mpmOgp2mNkgkJLwXN3X8Q0Fw3SS0DBPPOPhRxq/PyBsRFR9U7V6CxXJ1rorfdL/cRSCslZZ6cTCmidncfIS4Ab2Dhoy444BZGx+/1+qdl+mbvdJ+dXCsoY5p5txrN95HE4aAB+gLKMWiqvUjiLguNG19srhW2+WS3Vox90Up3HnHc7ucP/AEuBH2Lki2zETFp4LE2bv2b7Qhq2CShrtyK9UzA+RrBhk7M45Rg9meBH4pI7iCbuvMtguclj1VY7hE7dLK2KCTj99FK4RvB+zrB35Wj2L00vgfSmiU6LjROH/jVv+WbPrERF4yCIiAiIgIiICIiAiIg0dtqoZKTXNDWHPI11vELT3b8Mjif0kTD8u6fYqNUVEVJTyzzyshgiaXySSODWsaBkkk8AAO9eitcaPg1rYn0MknN6iNwmpakN3jDKAQHY7wQS0jIy1xGQeI8+3SjqbHc32u6wczrhnETzlszf6cbux7eziOIzhwacgfeeidKpxsCMK/6qfpmTF96nja5oVxAGtNPEngALrB/nQbXNCkgDWmniT3dKwf51ZuY0x/7vF/cCcyp/9hF/cC9a2LnHL7sGhrHsgOn7tXWy47NLPqymqLnLURahnkpwRTyyl5EzXgyF7A5wG6CDgDIVjuOgr1LYtsdLDQDlL+2QWtgljAnzQMiH42GddpHWx2Z7OK24i0U6Jh0xaP6ymMuvpVpy36e1bobU1zrbfp0X+kvttoopuTrYoJKKoghMRa7fOHMIwctyQc8DlSezbUtj2bbPtOab1Rf7PZL7b6GKKqoKu5QNkidu5wRv+wg5HBbQXW+lhlcXPiY9x73NBKzpwNSb0Tnx6985dPWKwdrehmhpOs9PAOGQTdYOI7P6f2Kaseo7TqekfVWa6UV2pmPMTpqGoZMxrwAS0uaSAcEHH2hZfMqf/YRf3Am9DSuiiYzEkz9yOGJmXyOPc1oGXH7AFupiu/6pjl9xm2qifddRWOgjBc+or4SQD+Ix4kkP9xjl6fWutluzyWwPferqzcuk8XJRUxIPNYyckEjgXuw3eI4DdAHeXbFXw/pbSqNIxopw5vFPT19LPhFhEReGgiIgIiICIiAiIgIiICwrvZLfqCiNJc6GnuFKSHcjUxCRuR2HBHaPas1FYmaZvE7xRJNiOj3k7tvqoQTndhuVSwfoAkwP0Lh9Bukfda/9rVfmq/IuzbtK/dq5yt5UH6DdI+61/wC1qvzU+g3SPutf+1qvzVfkV27Sv3aucl5UH6DdI+61/wC1qvzU+g3SPutf+1qvzVfkTbtK/dq5yXlQhsO0gM5o65wPaDdavzVYNO6HsOlC59qtdPSTOG66oDd6Z49jpHZcR9hKnUWuvSsfFjVrxJmOuZLyIiLlQREQEREBERB//9k=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Node definition\n",
    "def tool_calling_ollama(state: MessagesState):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ollama_with_tools.invoke(\n",
    "                state[\"messages\"], \n",
    "                config={\n",
    "                            \"callbacks\": [langfuse_handler]\n",
    "                       }\n",
    "                )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_ollama\", tool_calling_ollama)\n",
    "builder.add_edge(START, \"tool_calling_ollama\")\n",
    "builder.add_edge(\"tool_calling_ollama\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b3960-ceb0-4183-812a-ca4c75803e80",
   "metadata": {},
   "source": [
    "As we can see, we only defined the graph, but we didnt invoke the whole application, it is just a simple graph with a start a central node and an end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2fff5-12ec-47aa-81cc-35940ca7be96",
   "metadata": {},
   "source": [
    "## Now let's invoke the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "669c9f5b-be7e-45e3-9655-72db4245b793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  None (959f1a60-b9a2-406d-b0e9-17e048efa4e8)\n",
      " Call ID: 959f1a60-b9a2-406d-b0e9-17e048efa4e8\n",
      "  Args:\n"
     ]
    }
   ],
   "source": [
    "# the function is not being called\n",
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a086a780-ce48-44ef-9190-e627bafc91bf",
   "metadata": {},
   "source": [
    "As you can suppose here, llama model is smart and it detects that no function call is needed here, thats why the tool calls is None.\n",
    "\n",
    "As a homework for the reader, investigate why both generations are being attached in the same trace (LangFuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20cf019-91d3-4630-8aee-6490660a98fe",
   "metadata": {},
   "source": [
    "## Lets use a message that makes llama call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c9d1e7e-7c8c-49d5-9f35-197240bab082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I would like to know how much is 5674356 by 43526789\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (545ddc4b-75f6-4175-ab05-a34c1dcf6096)\n",
      " Call ID: 545ddc4b-75f6-4175-ab05-a34c1dcf6096\n",
      "  Args:\n",
      "    a: 5674356\n",
      "    b: 43526789\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke(\n",
    "    {\n",
    "        \"messages\": HumanMessage(content=\"I would like to know how much is 5674356 by 43526789\")\n",
    "    },\n",
    "    config={\n",
    "            \"callbacks\": [langfuse_handler]\n",
    "        })\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1a47b-d78c-4e57-a3fe-c044696abe63",
   "metadata": {},
   "source": [
    "Important note here, as you can see in LangFuse even using the same Ollama model the trace name changes to LangGraph.\n",
    "\n",
    "As well we cannot see the result/response from the tool call in LangFuse due to an open issue: https://github.com/langfuse/langfuse/issues/1911"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29ab12-b240-4a44-b405-392115b4917d",
   "metadata": {},
   "source": [
    "## Chaining several times the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdbb8b83-79f3-47d8-bbe5-259f90495e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e678415-6b1e-4949-a075-03bbb0fb478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "ollama_model = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0\n",
    ")\n",
    "tools = [add]\n",
    "ollama_with_tools = ollama_model.bind_tools(tools, parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb16ca9d-775d-488a-817b-448d20d55288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# Node\n",
    "def arithmetic_assistant(state: MessagesState):\n",
    "   return {\n",
    "       \"messages\": [\n",
    "           ollama_with_tools.invoke(\n",
    "               # Concatenating the System message (Act as a ...) and the message (Math Operation)\n",
    "               [sys_msg] + state[\"messages\"],\n",
    "               config={\n",
    "                    \"callbacks\": [langfuse_handler]\n",
    "                }\n",
    "            )]\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd155fe4-f75b-43d6-80de-8dbf0b9050d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"arithmetic_assistant\", arithmetic_assistant)  # This concate the message with the sys msg\n",
    "builder.add_node(\"tools\", ToolNode(tools))  # This execute the tools if needed\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"arithmetic_assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"arithmetic_assistant\",\n",
    "    tools_condition, # Checks the Node response and directs to the \"tools\" node if a tool is needed; otherwise, it ends the flow.\n",
    ")\n",
    "\n",
    "builder.add_edge(\"tools\", \"arithmetic_assistant\")\n",
    "\n",
    "# Note the name contains ReAct, it should give you an idea of what is going on here\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce06e0-acfd-4fb0-9724-990aa28545fa",
   "metadata": {},
   "source": [
    "Lets run our new graph that gives llama the super power of using tools several times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b9ec1f1-c143-4fdf-866f-c465a3076e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"Think step by step, and only use the tools provided. Add 200 and 555. add to the output a 2\")]\n",
    "messages = react_graph.invoke({\"messages\": messages}, config={\"callbacks\": [langfuse_handler]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4d0aed0-9805-4e19-a446-957488b62b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Think step by step, and only use the tools provided. Add 200 and 555. add to the output a 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (3b301471-33e2-4264-ad7b-bf45f20d71c2)\n",
      " Call ID: 3b301471-33e2-4264-ad7b-bf45f20d71c2\n",
      "  Args:\n",
      "    a: 200\n",
      "    b: 555\n",
      "  add (5009e6f3-5e0b-4fea-b082-a30da5648103)\n",
      " Call ID: 5009e6f3-5e0b-4fea-b082-a30da5648103\n",
      "  Args:\n",
      "    a: 755\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "755\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "757\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The final answer is $\\boxed{757}$.\n"
     ]
    }
   ],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c7826-4f86-440e-9dbf-2f2354592108",
   "metadata": {},
   "source": [
    "It worked! \n",
    "\n",
    "Lets try to invoke the graph again and continue \"chatting\" with my llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54f17658-8dff-4488-893c-8168508bb309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add that by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (5cd0d877-56d9-4d65-8e13-9da162c6b1a6)\n",
      " Call ID: 5cd0d877-56d9-4d65-8e13-9da162c6b1a6\n",
      "  Args:\n",
      "    a: that\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "Error: 1 validation error for add\n",
      "a\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='that', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/int_parsing\n",
      " Please fix your mistakes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (c397b456-e72d-41b9-ba9e-f8ebdf33a868)\n",
      " Call ID: c397b456-e72d-41b9-ba9e-f8ebdf33a868\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 2 is 5.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Add that by 2.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages}, config={\"callbacks\": [langfuse_handler]})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f3553c-56ed-4f24-a8d1-7607534a355d",
   "metadata": {},
   "source": [
    "It looks my llama forgot the previous answer \"757\", let me ask it again to check if it was an hallucination or not.\n",
    "\n",
    "**Quick Note:** Check LangFuse Trace observations, you will see an interesting behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b19db2ad-a78b-44bb-a430-a34ac891114e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply that by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (58416a19-487f-454e-8020-672ca0721bd8)\n",
      " Call ID: 58416a19-487f-454e-8020-672ca0721bd8\n",
      "  Args:\n",
      "    a: 1\n",
      "    b: 1\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (9d2a9d4b-3322-49e6-9358-81577593702d)\n",
      " Call ID: 9d2a9d4b-3322-49e6-9358-81577593702d\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 1\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 1 by 2 is 2.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Multiply that by 2.\")]\n",
    "messages = react_graph.invoke({\"messages\": messages}, config={\"callbacks\": [langfuse_handler]})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc5aa4-173e-430b-bc39-44eb782c5570",
   "metadata": {},
   "source": [
    "Ok it looks my llama is not storing responses between invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab446be-2999-45de-bd1b-a7428ddda93c",
   "metadata": {},
   "source": [
    "### As we can see every time we invoke the graph/application we get kind of stateless result\n",
    "\n",
    "But as we are using LangGraph, we can configure easily memory for our Llama, lets do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5499cf1d-3a1f-4fa5-8bf4-6ab4505fbb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "# By passing a memory checkpointer when compiling pur graph we can now store data from invocations\n",
    "react_graph_memory = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "233deb56-c26e-49a4-b834-b0dd82a9055f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (9138d531-527a-4968-bf93-c79be9beca93)\n",
      " Call ID: 9138d531-527a-4968-bf93-c79be9beca93\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 4 is 7.\n"
     ]
    }
   ],
   "source": [
    "# Specify a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}, \"callbacks\": [langfuse_handler]}\n",
    "\n",
    "# Specify an input\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "\n",
    "# Run\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6efa7d49-0432-4667-bc4b-429204959d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (9138d531-527a-4968-bf93-c79be9beca93)\n",
      " Call ID: 9138d531-527a-4968-bf93-c79be9beca93\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 4 is 7.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add the result by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (3054d20f-9e45-444a-850c-58e4c710960d)\n",
      " Call ID: 3054d20f-9e45-444a-850c-58e4c710960d\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 7 and 2 is 9.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Add the result by 2.\")]\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14a664-66d3-46c2-94ae-89b10afb5523",
   "metadata": {},
   "source": [
    "Now it works, we can see LangFuse to check how the trace take into account previous messages and add those into the input for the tool_calls and generations to get the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e144e557-48ed-4c11-a8d4-6d7d8bbdf78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (9138d531-527a-4968-bf93-c79be9beca93)\n",
      " Call ID: 9138d531-527a-4968-bf93-c79be9beca93\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 4 is 7.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add the result by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (3054d20f-9e45-444a-850c-58e4c710960d)\n",
      " Call ID: 3054d20f-9e45-444a-850c-58e4c710960d\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 7 and 2 is 9.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Based on the result number, tell me that number of good points of using LangGraph for my LLM application\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (d9bbb535-8344-4a1a-9a95-f4aa81a8d550)\n",
      " Call ID: d9bbb535-8344-4a1a-9a95-f4aa81a8d550\n",
      "  Args:\n",
      "    a: 9\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "19\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 9 and 10 is 19.\n",
      "\n",
      "Based on the result number, I can tell you that there are 19 good points of using LangGraph for your LLM application.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Based on the result number, create a list that number of good points of using LangGraph for my LLM application\")]\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafc01ef-68a7-4f90-8935-ea2c7a3d5ab0",
   "metadata": {},
   "source": [
    "As we can see not always the llama takes the right decision of doing a tool call or just invoking llama, thats why we need better prompts, better guardrails and checkers.\n",
    "\n",
    "Lets try to run it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d848e02-c7b6-46c2-8484-24685b67d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (9138d531-527a-4968-bf93-c79be9beca93)\n",
      " Call ID: 9138d531-527a-4968-bf93-c79be9beca93\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 4 is 7.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add the result by 2.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (3054d20f-9e45-444a-850c-58e4c710960d)\n",
      " Call ID: 3054d20f-9e45-444a-850c-58e4c710960d\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 7 and 2 is 9.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Based on the result number, tell me that number of good points of using LangGraph for my LLM application\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (d9bbb535-8344-4a1a-9a95-f4aa81a8d550)\n",
      " Call ID: d9bbb535-8344-4a1a-9a95-f4aa81a8d550\n",
      "  Args:\n",
      "    a: 9\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "19\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 9 and 10 is 19.\n",
      "\n",
      "Based on the result number, I can tell you that there are 19 good points of using LangGraph for your LLM application.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Based on the result number N, create a list with N good points about using LangGraph for my LLM application\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (f501acf2-1fc6-4958-af78-09230173db36)\n",
      " Call ID: f501acf2-1fc6-4958-af78-09230173db36\n",
      "  Args:\n",
      "    a: 19\n",
      "    b: 1\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "20\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 19 and 1 is 20.\n",
      "\n",
      "Here are the 20 good points about using LangGraph for your LLM application:\n",
      "\n",
      "1. **Improved Language Understanding**: LangGraph enables your LLM to better comprehend language nuances, idioms, and context-dependent expressions.\n",
      "2. **Enhanced Contextualization**: It helps your model to capture contextual relationships between words, phrases, and sentences, leading to more accurate predictions.\n",
      "3. **Better Entity Recognition**: LangGraph's entity recognition capabilities enable your LLM to identify and understand specific entities like names, locations, and organizations.\n",
      "4. **Improved Sentiment Analysis**: By leveraging LangGraph's sentiment analysis features, your model can better detect emotions and sentiments in text data.\n",
      "5. **Increased Accuracy**: The use of LangGraph leads to improved accuracy in predicting outcomes, making it an essential tool for LLM applications.\n",
      "6. **Faster Training Times**: With LangGraph, you can train your LLM faster, reducing the time-to-market for your application.\n",
      "7. **Scalability**: It allows your model to scale more efficiently, handling large volumes of data with ease.\n",
      "8. **Improved Model Interpretability**: LangGraph provides insights into how your model is making predictions, enabling better decision-making.\n",
      "9. **Better Handling of Ambiguity**: It helps your LLM to handle ambiguous language and context-dependent expressions more effectively.\n",
      "10. **Enhanced Support for Multiple Languages**: LangGraph enables your model to support multiple languages, expanding its reach and usability.\n",
      "11. **Improved Handling of Idioms and Colloquialisms**: It helps your LLM to better understand idioms, colloquialisms, and other language-specific expressions.\n",
      "12. **Better Contextual Understanding of Emotions**: LangGraph's contextual understanding of emotions enables your model to better detect emotional nuances in text data.\n",
      "13. **Improved Handling of Sarcasm and Irony**: It helps your LLM to better understand sarcasm and irony, reducing the risk of misinterpretation.\n",
      "14. **Enhanced Support for Specialized Domains**: LangGraph enables your model to support specialized domains like medicine, law, or finance, where language nuances are critical.\n",
      "15. **Improved Handling of Abstract Concepts**: It helps your LLM to better understand abstract concepts and ideas, enabling more accurate predictions.\n",
      "16. **Better Contextual Understanding of Relationships**: LangGraph's contextual understanding of relationships enables your model to better detect connections between entities and concepts.\n",
      "17. **Improved Handling of Complex Sentences**: It helps your LLM to better understand complex sentences with multiple clauses and dependencies.\n",
      "18. **Enhanced Support for Conversational Dialogue**: LangGraph enables your model to support conversational dialogue, making it more suitable for chatbots and virtual assistants.\n",
      "19. **Improved Handling of Multi-Step Reasoning**: It helps your LLM to better handle multi-step reasoning and decision-making processes.\n",
      "20. **Better Contextual Understanding of Prior Knowledge**: LangGraph's contextual understanding of prior knowledge enables your model to better incorporate existing knowledge into its predictions.\n",
      "\n",
      "By using LangGraph for your LLM application, you can leverage these 20 good points to improve the accuracy, efficiency, and effectiveness of your model.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Based on the result number N, create a list with N good points about using LangGraph for my LLM application\")]\n",
    "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce0c0b-9c20-42eb-9105-8c5ce11cf785",
   "metadata": {},
   "source": [
    "Finally we got our lists of good reasons about using LangGraph, but in the call there were some extra steps that were hallucinations. \n",
    "On next modules you will see how to handle hallucinations and will get more deep understanding on LangGraph, LangChain, Llamas and more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a279ef-09f0-4650-9478-1020146abadf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
